{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 104/104 [00:00<00:00, 4249.67 examples/s]\n",
      "Map: 100%|██████████| 104/104 [00:00<00:00, 21012.94 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 16%|█▌        | 102/650 [00:13<00:52, 10.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6105, 'grad_norm': 0.7972972989082336, 'learning_rate': 4.230769230769231e-05, 'epoch': 7.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 202/650 [00:28<00:56,  7.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0122, 'grad_norm': 0.06653542071580887, 'learning_rate': 3.461538461538462e-05, 'epoch': 15.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 302/650 [00:42<01:02,  5.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0048, 'grad_norm': 0.03561079129576683, 'learning_rate': 2.6923076923076923e-05, 'epoch': 23.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 402/650 [00:56<00:23, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.003, 'grad_norm': 0.028323112055659294, 'learning_rate': 1.923076923076923e-05, 'epoch': 30.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 502/650 [01:10<00:17,  8.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0022, 'grad_norm': 0.022158294916152954, 'learning_rate': 1.153846153846154e-05, 'epoch': 38.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 602/650 [01:25<00:08,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0021, 'grad_norm': 0.022441180422902107, 'learning_rate': 3.846153846153847e-06, 'epoch': 46.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 650/650 [01:35<00:00,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 95.3521, 'train_samples_per_second': 54.535, 'train_steps_per_second': 6.817, 'train_loss': 0.09779059088000884, 'epoch': 50.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./intent_model/tokenizer_config.json',\n",
       " './intent_model/special_tokens_map.json',\n",
       " './intent_model/vocab.txt',\n",
       " './intent_model/added_tokens.json')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import DataCollatorWithPadding\n",
    "import torch\n",
    "\n",
    "# Load dataset\n",
    "# datafile = '../data/Bitext.csv'\n",
    "datafile = './data/bert_input.csv'\n",
    "df = pd.read_csv(datafile)\n",
    "df = df[['instruction', 'intent']]\n",
    "print(len(df))\n",
    "\n",
    "# Convert to Hugging Face dataset\n",
    "intent_dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# get device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example['instruction'], padding='max_length', truncation=True, max_length=128)\n",
    "\n",
    "# Apply tokenization to the dataset\n",
    "intent_dataset = intent_dataset.map(tokenize_function, remove_columns=[\"instruction\"])\n",
    "\n",
    "# Map 'intent' to numerical labels\n",
    "intent_labels = {intent: idx for idx, intent in enumerate(df['intent'].unique())}\n",
    "intent_dataset = intent_dataset.map(lambda x: {'labels': intent_labels[x['intent']]})\n",
    "\n",
    "# Number of intents\n",
    "num_intents = len(df['intent'].unique())\n",
    "print(num_intents)\n",
    "\n",
    "# Load DistilBERT model for sequence classification\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=num_intents)\n",
    "\n",
    "# Data collator (use for sequence classification, handles padding)\n",
    "data_collator = DataCollatorWithPadding(tokenizer, padding='max_length', max_length=128)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./intent_model',\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    num_train_epochs=50,\n",
    "    per_device_train_batch_size=8,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,  # Log every 10 steps\n",
    "    save_steps=500,\n",
    "    disable_tqdm=False,\n",
    ")\n",
    "\n",
    "\n",
    "# Trainer setup\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=intent_dataset,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Train the model with tqdm progress bar\n",
    "trainer.train()\n",
    "tokenizer.save_pretrained('./intent_model')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the intent labels\n",
    "import json\n",
    "with open('./intent_model/intent_labels.json', 'w') as f:\n",
    "    json.dump(intent_labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted intent ID: 2\n",
      "Predicted intent: list_orders\n"
     ]
    }
   ],
   "source": [
    "# Function to test the trained model\n",
    "def test_model(input_text, model, tokenizer):\n",
    "    # Tokenize the input text without 'token_type_ids'\n",
    "    inputs = tokenizer(input_text, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "    \n",
    "    # Remove 'token_type_ids' from the input if it exists\n",
    "    inputs.pop('token_type_ids', None)\n",
    "    \n",
    "    # Move tensors to the appropriate device (GPU if available)\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Get predicted label (the class with the highest score)\n",
    "    logits = outputs.logits\n",
    "    predicted_class_id = torch.argmax(logits, dim=-1).item()\n",
    "    \n",
    "    return predicted_class_id\n",
    "\n",
    "# Test the trained model with a sample input\n",
    "input_text = \"[INT] [BOT] [USR] Hey i want to know list my orders\"\n",
    "predicted_class_id = test_model(input_text, model, tokenizer)\n",
    "\n",
    "# Print the predicted intent\n",
    "print(f\"Predicted intent ID: {predicted_class_id}\")\n",
    "\n",
    "# Optionally map the predicted intent ID back to the intent label\n",
    "# get key from value\n",
    "predicted_intent = list(intent_labels.keys())[list(intent_labels.values()).index(predicted_class_id)]\n",
    "print(f\"Predicted intent: {predicted_intent}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['track_order', 'give_order_id', 'list_orders',\n",
       "       'give_list_order_params', 'cancel_order', 'give_reason',\n",
       "       'confirm_command'], dtype=object)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.intent.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "Predicted intent ID: 1\n",
      "Predicted intent: give_order_id\n",
      "Instruction: [INT] cancel_order [BOT] Can you confirm the cancellation of your most recent order? [USR] No, don’t proceed with it.\n",
      "True intent: confirm_command\n",
      "Predicted intent: confirm_command\n",
      "\n",
      "Instruction: [INT] [BOT]  [USR] Where is my order?\n",
      "True intent: track_order\n",
      "Predicted intent: track_order\n",
      "\n",
      "Instruction: [INT] [BOT]  [USR] Can you check my order 12345?\n",
      "True intent: track_order\n",
      "Predicted intent: track_order\n",
      "\n",
      "Instruction: [INT] [BOT]  [USR] I’d like to know the status of my order.\n",
      "True intent: track_order\n",
      "Predicted intent: track_order\n",
      "\n",
      "Instruction: [INT] cancel_order [BOT] Are you sure you want to cancel this order? [USR] Yes, I am sure.\n",
      "True intent: confirm_command\n",
      "Predicted intent: confirm_command\n",
      "\n",
      "Instruction: [INT] [BOT]  [USR] I want to cancel order 998877.\n",
      "True intent: cancel_order\n",
      "Predicted intent: cancel_order\n",
      "\n",
      "Instruction: [INT] cancel_order [BOT] What’s the reason for canceling this order? [USR] I ordered the wrong item by mistake.\n",
      "True intent: give_reason\n",
      "Predicted intent: give_reason\n",
      "\n",
      "Instruction: [INT] list_orders [BOT] Sure? Are there any specific orders that you want to list? [USR] Yeah just list 5 of them between 12 June 2023 and 1 Jan 2024.\n",
      "True intent: give_list_order_params\n",
      "Predicted intent: give_list_order_params\n",
      "\n",
      "Instruction: [INT] track_order [BOT] Please provide your order number. [USR] 67890.\n",
      "True intent: give_order_id\n",
      "Predicted intent: give_order_id\n",
      "\n",
      "Instruction: [INT] list_orders [BOT] Do you need to filter anything? [USR] Yeah give me just 32 of them\n",
      "True intent: give_list_order_params\n",
      "Predicted intent: give_list_order_params\n",
      "\n",
      "Instruction: [INT] [BOT]  [USR] I’d like to cancel my most recent order.\n",
      "True intent: cancel_order\n",
      "Predicted intent: cancel_order\n",
      "\n",
      "Instruction: [INT] cancel_order [BOT] We are sorry to hear that. Can you provide a reason? [USR] The product doesn’t match the description.\n",
      "True intent: give_reason\n",
      "Predicted intent: give_reason\n",
      "\n",
      "Instruction: [INT] [BOT]  [USR] Hey can you cancel my last order?\n",
      "True intent: cancel_order\n",
      "Predicted intent: cancel_order\n",
      "\n",
      "Instruction: [INT] [BOT]  [USR] Cancel my order with ID 112233.\n",
      "True intent: cancel_order\n",
      "Predicted intent: cancel_order\n",
      "\n",
      "Instruction: [INT] cancel_order [BOT] Are you sure you want to cancel this order? [USR] No, ignore my request.\n",
      "True intent: confirm_command\n",
      "Predicted intent: confirm_command\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "# model = DistilBertForSequenceClassification.from_pretrained('./results/checkpoint-1500')\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Test the trained model with a sample input\n",
    "input_text = \"[INT] track_order [BOT] Please share the order ID [USR] 1231\"\n",
    "print(len(input_text))\n",
    "\n",
    "# Get the predicted intent ID\n",
    "predicted_class_id = test_model(input_text, model, tokenizer)\n",
    "\n",
    "# Print the predicted intent\n",
    "print(f\"Predicted intent ID: {predicted_class_id}\")\n",
    "print(f\"Predicted intent: {list(intent_labels.keys())[list(intent_labels.values()).index(predicted_class_id)]}\")\n",
    "\n",
    "# print probability scores of other intents\n",
    "def get_intent_probs(input_text, model, tokenizer):\n",
    "    # Tokenize the input text without 'token_type_ids'\n",
    "    inputs = tokenizer(input_text, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "    \n",
    "    # Remove 'token_type_ids' from the input if it exists\n",
    "    inputs.pop('token_type_ids', None)\n",
    "    \n",
    "    # Move tensors to the appropriate device (GPU if available)\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Get predicted label (the class with the highest score)\n",
    "    logits = outputs.logits\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "    \n",
    "    return probs\n",
    "\n",
    "# Get the probability scores for all intents\n",
    "probs = get_intent_probs(input_text, model, tokenizer)\n",
    "\n",
    "test_df = pd.read_csv(datafile)\n",
    "test_df = test_df[['instruction', 'intent']]\n",
    "\n",
    "# randomly take 15 samples\n",
    "test_df = test_df.sample(15)\n",
    "\n",
    "# Get the predicted intent ID for each sample\n",
    "test_df['predicted_intent_id'] = test_df['instruction'].apply(lambda x: test_model(x, model, tokenizer))\n",
    "\n",
    "# Map the predicted intent ID back to the intent label\n",
    "test_df['predicted_intent'] = test_df['predicted_intent_id'].apply(lambda x: list(intent_labels.keys())[list(intent_labels.values()).index(x)])\n",
    "\n",
    "for idx, row in test_df.iterrows():\n",
    "    print(f\"Instruction: {row['instruction']}\")\n",
    "    print(f\"True intent: {row['intent']}\")\n",
    "    print(f\"Predicted intent: {row['predicted_intent']}\")\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label to ID Mapping: {'B-AFFIRMATION': 0, 'B-CONFIRMATION': 1, 'B-COUNT': 2, 'B-END_DATE': 3, 'B-ORD': 4, 'B-REASON': 5, 'B-START_DATE': 6, 'I-END_DATE': 7, 'I-REASON': 8, 'I-START_DATE': 9, 'O': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 104/104 [00:00<00:00, 6982.90 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "special_tokens = [\"[INT]\", \"[BOT]\", \"[USR]\"]\n",
    "tokenizer.add_special_tokens({\"additional_special_tokens\": special_tokens})\n",
    "\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('./data/ner_data.csv')\n",
    "data[\"labels\"] = data[\"labels\"].apply(eval)\n",
    "\n",
    "# Extract unique labels and create a mapping\n",
    "unique_labels = sorted({label for labels in data[\"labels\"] for label in labels})\n",
    "label_to_id = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "\n",
    "print(\"Label to ID Mapping:\", label_to_id)\n",
    "\n",
    "# Convert DataFrame to list of dictionaries for Dataset.from_list\n",
    "data = data.to_dict(orient=\"records\")\n",
    "\n",
    "# Tokenize and align labels\n",
    "def tokenize_and_align_labels(examples):\n",
    "    # Tokenize the text\n",
    "    tokenized_inputs = tokenizer(examples[\"instruction\"], truncation=True, is_split_into_words=False)\n",
    "    tokens = tokenizer.convert_ids_to_tokens(tokenized_inputs[\"input_ids\"])\n",
    "    word_ids = tokenized_inputs.word_ids()\n",
    "    previous_word_idx = None\n",
    "    label_ids = []\n",
    "    labels = examples[\"labels\"]\n",
    "\n",
    "    # print(f\"{'Token':<15} {'Word':<15} {'Label':<15}\")\n",
    "\n",
    "    for i, word_idx in enumerate(word_ids):\n",
    "        token = tokens[i]  # Current token\n",
    "\n",
    "        if word_idx is None:  # Special tokens ([CLS], [SEP], padding)\n",
    "            word = \"N/A\"\n",
    "            label = \"Special\"\n",
    "            label_ids.append(-100)\n",
    "        elif word_idx != previous_word_idx:  # First subword\n",
    "            word = examples[\"instruction\"][word_idx]\n",
    "            label = labels[word_idx]\n",
    "            label_ids.append(label_to_id[label])\n",
    "        else:  # Subword token\n",
    "            word = examples[\"instruction\"][word_idx]\n",
    "            label = labels[word_idx]\n",
    "            token = f\"Subword: {token} (Part of: {word})\"\n",
    "            label_ids.append(-100)\n",
    "\n",
    "        # Print token, word, and label in the same line\n",
    "        # print(f\"{token:<15} {word:<15} {label:<15}\")\n",
    "        previous_word_idx = word_idx\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = label_ids\n",
    "    return tokenized_inputs\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "dataset = Dataset.from_list(data)\n",
    "\n",
    "# Map tokenizer to the dataset\n",
    "dataset = dataset.map(tokenize_and_align_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the label_to_id mapping\n",
    "import json\n",
    "with open('./ner_model/entity_labels.json', 'w') as f:\n",
    "    json.dump(label_to_id, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label to ID Mapping: {'B-AFFIRMATION': 0, 'B-CONFIRMATION': 1, 'B-COUNT': 2, 'B-END_DATE': 3, 'B-ORD': 4, 'B-REASON': 5, 'B-START_DATE': 6, 'I-END_DATE': 7, 'I-REASON': 8, 'I-START_DATE': 9, 'O': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 93/93 [00:00<00:00, 5872.08 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Map: 100%|██████████| 11/11 [00:00<00:00, 2829.82 examples/s]\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/harshit/IITH/Sem7/CyberSecurityAndAI/cyber_security_project/chatbot_venv/lib/python3.12/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_12434/4147611080.py:74: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "  1%|          | 47/4700 [00:02<04:53, 15.87it/s]\n",
      "  1%|          | 47/4700 [00:03<04:53, 15.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22458265721797943, 'eval_runtime': 0.0699, 'eval_samples_per_second': 157.387, 'eval_steps_per_second': 85.847, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 93/4700 [00:07<04:49, 15.92it/s]\n",
      "  2%|▏         | 94/4700 [00:07<04:49, 15.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11737439781427383, 'eval_runtime': 0.0701, 'eval_samples_per_second': 156.918, 'eval_steps_per_second': 85.592, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 103/4700 [00:10<09:48,  7.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5838, 'grad_norm': 1.2947421073913574, 'learning_rate': 9.787234042553192e-06, 'epoch': 2.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 141/4700 [00:12<04:48, 15.81it/s]\n",
      "  3%|▎         | 141/4700 [00:12<04:48, 15.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.08534422516822815, 'eval_runtime': 0.0694, 'eval_samples_per_second': 158.555, 'eval_steps_per_second': 86.484, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 187/4700 [00:17<04:47, 15.67it/s]\n",
      "  4%|▍         | 188/4700 [00:17<04:47, 15.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0520344041287899, 'eval_runtime': 0.073, 'eval_samples_per_second': 150.647, 'eval_steps_per_second': 82.171, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 203/4700 [00:19<06:23, 11.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1064, 'grad_norm': 2.5115087032318115, 'learning_rate': 9.574468085106385e-06, 'epoch': 4.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 235/4700 [00:21<04:43, 15.75it/s]\n",
      "  5%|▌         | 235/4700 [00:22<04:43, 15.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03842921182513237, 'eval_runtime': 0.0699, 'eval_samples_per_second': 157.473, 'eval_steps_per_second': 85.894, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 281/4700 [00:26<04:40, 15.74it/s]\n",
      "  6%|▌         | 282/4700 [00:26<04:40, 15.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04386845603585243, 'eval_runtime': 0.0708, 'eval_samples_per_second': 155.411, 'eval_steps_per_second': 84.77, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 303/4700 [00:29<05:14, 13.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0434, 'grad_norm': 0.05798317492008209, 'learning_rate': 9.361702127659576e-06, 'epoch': 6.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 329/4700 [00:31<04:36, 15.83it/s]\n",
      "  7%|▋         | 329/4700 [00:31<04:36, 15.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03568371757864952, 'eval_runtime': 0.0695, 'eval_samples_per_second': 158.342, 'eval_steps_per_second': 86.368, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 375/4700 [00:36<04:36, 15.64it/s]\n",
      "  8%|▊         | 376/4700 [00:36<04:36, 15.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03462174907326698, 'eval_runtime': 0.07, 'eval_samples_per_second': 157.037, 'eval_steps_per_second': 85.657, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 403/4700 [00:39<04:44, 15.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0257, 'grad_norm': 0.03279486671090126, 'learning_rate': 9.148936170212767e-06, 'epoch': 8.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 423/4700 [00:40<04:30, 15.82it/s]\n",
      "  9%|▉         | 423/4700 [00:41<04:30, 15.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.032127682119607925, 'eval_runtime': 0.0704, 'eval_samples_per_second': 156.156, 'eval_steps_per_second': 85.176, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 469/4700 [00:45<04:31, 15.58it/s]\n",
      " 10%|█         | 470/4700 [00:45<04:31, 15.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03229452669620514, 'eval_runtime': 0.0703, 'eval_samples_per_second': 156.534, 'eval_steps_per_second': 85.382, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 503/4700 [00:50<04:30, 15.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0111, 'grad_norm': 0.03961629793047905, 'learning_rate': 8.936170212765958e-06, 'epoch': 10.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 517/4700 [00:50<04:24, 15.81it/s]\n",
      " 11%|█         | 517/4700 [00:51<04:24, 15.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.030216870829463005, 'eval_runtime': 0.0682, 'eval_samples_per_second': 161.206, 'eval_steps_per_second': 87.93, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 563/4700 [00:55<04:22, 15.76it/s]\n",
      " 12%|█▏        | 564/4700 [00:55<04:22, 15.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03398739919066429, 'eval_runtime': 0.0712, 'eval_samples_per_second': 154.486, 'eval_steps_per_second': 84.265, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 603/4700 [01:00<04:22, 15.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0081, 'grad_norm': 0.05680681765079498, 'learning_rate': 8.72340425531915e-06, 'epoch': 12.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 611/4700 [01:00<04:19, 15.78it/s]\n",
      " 13%|█▎        | 611/4700 [01:00<04:19, 15.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.030818527564406395, 'eval_runtime': 0.0673, 'eval_samples_per_second': 163.337, 'eval_steps_per_second': 89.093, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 657/4700 [01:05<04:19, 15.58it/s]\n",
      " 14%|█▍        | 658/4700 [01:05<04:19, 15.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.048558853566646576, 'eval_runtime': 0.0699, 'eval_samples_per_second': 157.258, 'eval_steps_per_second': 85.777, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 703/4700 [01:10<04:13, 15.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.008, 'grad_norm': 0.4102288782596588, 'learning_rate': 8.510638297872341e-06, 'epoch': 14.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 705/4700 [01:10<04:14, 15.73it/s]\n",
      " 15%|█▌        | 705/4700 [01:10<04:14, 15.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03696509450674057, 'eval_runtime': 0.066, 'eval_samples_per_second': 166.555, 'eval_steps_per_second': 90.848, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 751/4700 [01:15<04:12, 15.61it/s]\n",
      " 16%|█▌        | 752/4700 [01:15<04:12, 15.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.049430426210165024, 'eval_runtime': 0.071, 'eval_samples_per_second': 154.924, 'eval_steps_per_second': 84.504, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 799/4700 [01:20<04:05, 15.86it/s]\n",
      " 17%|█▋        | 799/4700 [01:20<04:05, 15.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03298383578658104, 'eval_runtime': 0.0692, 'eval_samples_per_second': 158.857, 'eval_steps_per_second': 86.649, 'epoch': 17.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 803/4700 [01:22<22:04,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0049, 'grad_norm': 0.026557985693216324, 'learning_rate': 8.297872340425532e-06, 'epoch': 17.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 845/4700 [01:25<04:03, 15.80it/s]\n",
      " 18%|█▊        | 846/4700 [01:25<04:03, 15.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03578469529747963, 'eval_runtime': 0.0714, 'eval_samples_per_second': 154.146, 'eval_steps_per_second': 84.08, 'epoch': 18.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 893/4700 [01:30<04:01, 15.75it/s]\n",
      " 19%|█▉        | 893/4700 [01:30<04:01, 15.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.044258590787649155, 'eval_runtime': 0.0689, 'eval_samples_per_second': 159.587, 'eval_steps_per_second': 87.048, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 903/4700 [01:33<08:29,  7.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0033, 'grad_norm': 0.01172460988163948, 'learning_rate': 8.085106382978723e-06, 'epoch': 19.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 939/4700 [01:35<03:57, 15.84it/s]\n",
      " 20%|██        | 940/4700 [01:35<03:57, 15.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.058734867721796036, 'eval_runtime': 0.0692, 'eval_samples_per_second': 159.028, 'eval_steps_per_second': 86.743, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 987/4700 [01:41<03:56, 15.72it/s]\n",
      " 21%|██        | 987/4700 [01:41<03:56, 15.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04295680671930313, 'eval_runtime': 0.0708, 'eval_samples_per_second': 155.275, 'eval_steps_per_second': 84.695, 'epoch': 21.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 1003/4700 [01:44<05:21, 11.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0026, 'grad_norm': 0.7668514847755432, 'learning_rate': 7.872340425531916e-06, 'epoch': 21.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 1033/4700 [01:46<03:52, 15.75it/s]\n",
      " 22%|██▏       | 1034/4700 [01:46<03:52, 15.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04735280200839043, 'eval_runtime': 0.073, 'eval_samples_per_second': 150.646, 'eval_steps_per_second': 82.17, 'epoch': 22.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 1081/4700 [01:50<03:50, 15.68it/s]\n",
      " 23%|██▎       | 1081/4700 [01:51<03:50, 15.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03867730870842934, 'eval_runtime': 0.0763, 'eval_samples_per_second': 144.259, 'eval_steps_per_second': 78.687, 'epoch': 23.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 1103/4700 [01:54<04:14, 14.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0019, 'grad_norm': 0.017853640019893646, 'learning_rate': 7.659574468085107e-06, 'epoch': 23.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 1127/4700 [01:55<03:41, 16.11it/s]\n",
      " 24%|██▍       | 1128/4700 [01:55<03:41, 16.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.037846263498067856, 'eval_runtime': 0.0695, 'eval_samples_per_second': 158.29, 'eval_steps_per_second': 86.34, 'epoch': 24.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1175/4700 [02:00<03:45, 15.66it/s]\n",
      " 25%|██▌       | 1175/4700 [02:00<03:45, 15.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04152911901473999, 'eval_runtime': 0.0695, 'eval_samples_per_second': 158.247, 'eval_steps_per_second': 86.316, 'epoch': 25.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 1203/4700 [02:04<03:50, 15.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0015, 'grad_norm': 0.021570656448602676, 'learning_rate': 7.446808510638298e-06, 'epoch': 25.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 1221/4700 [02:05<03:42, 15.64it/s]\n",
      " 26%|██▌       | 1222/4700 [02:05<03:42, 15.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03805603086948395, 'eval_runtime': 0.0717, 'eval_samples_per_second': 153.336, 'eval_steps_per_second': 83.638, 'epoch': 26.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 1269/4700 [02:10<03:38, 15.72it/s]\n",
      " 27%|██▋       | 1269/4700 [02:10<03:38, 15.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.037800054997205734, 'eval_runtime': 0.0718, 'eval_samples_per_second': 153.297, 'eval_steps_per_second': 83.616, 'epoch': 27.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 1303/4700 [02:14<03:39, 15.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0014, 'grad_norm': 0.05468226224184036, 'learning_rate': 7.234042553191491e-06, 'epoch': 27.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 1315/4700 [02:15<03:35, 15.72it/s]\n",
      " 28%|██▊       | 1316/4700 [02:15<03:35, 15.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03698619827628136, 'eval_runtime': 0.0707, 'eval_samples_per_second': 155.488, 'eval_steps_per_second': 84.812, 'epoch': 28.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 1363/4700 [02:19<03:31, 15.77it/s]\n",
      " 29%|██▉       | 1363/4700 [02:19<03:31, 15.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03821110725402832, 'eval_runtime': 0.0705, 'eval_samples_per_second': 155.997, 'eval_steps_per_second': 85.09, 'epoch': 29.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 1403/4700 [02:24<03:27, 15.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0012, 'grad_norm': 0.008205904625356197, 'learning_rate': 7.021276595744682e-06, 'epoch': 29.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 1409/4700 [02:24<03:29, 15.73it/s]\n",
      " 30%|███       | 1410/4700 [02:24<03:29, 15.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0391620434820652, 'eval_runtime': 0.0711, 'eval_samples_per_second': 154.691, 'eval_steps_per_second': 84.377, 'epoch': 30.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 1457/4700 [02:29<03:25, 15.74it/s]\n",
      " 31%|███       | 1457/4700 [02:29<03:25, 15.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04019337520003319, 'eval_runtime': 0.0695, 'eval_samples_per_second': 158.215, 'eval_steps_per_second': 86.299, 'epoch': 31.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 1503/4700 [02:34<03:22, 15.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.001, 'grad_norm': 0.023866651579737663, 'learning_rate': 6.808510638297873e-06, 'epoch': 31.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 32%|███▏      | 1504/4700 [02:34<03:22, 15.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.040582384914159775, 'eval_runtime': 0.0695, 'eval_samples_per_second': 158.381, 'eval_steps_per_second': 86.39, 'epoch': 32.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1551/4700 [02:39<03:18, 15.88it/s]\n",
      " 33%|███▎      | 1551/4700 [02:39<03:18, 15.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03847317397594452, 'eval_runtime': 0.0685, 'eval_samples_per_second': 160.486, 'eval_steps_per_second': 87.538, 'epoch': 33.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 1597/4700 [02:44<03:17, 15.74it/s]\n",
      " 34%|███▍      | 1598/4700 [02:44<03:17, 15.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03844139352440834, 'eval_runtime': 0.0721, 'eval_samples_per_second': 152.465, 'eval_steps_per_second': 83.163, 'epoch': 34.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 1603/4700 [02:46<10:03,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.001, 'grad_norm': 0.008173436857759953, 'learning_rate': 6.595744680851064e-06, 'epoch': 34.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 1645/4700 [02:49<03:12, 15.87it/s]\n",
      " 35%|███▌      | 1645/4700 [02:49<03:12, 15.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.038352567702531815, 'eval_runtime': 0.0683, 'eval_samples_per_second': 161.142, 'eval_steps_per_second': 87.896, 'epoch': 35.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 1691/4700 [02:53<03:14, 15.49it/s]\n",
      " 36%|███▌      | 1692/4700 [02:53<03:14, 15.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03909435495734215, 'eval_runtime': 0.0713, 'eval_samples_per_second': 154.274, 'eval_steps_per_second': 84.149, 'epoch': 36.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 1703/4700 [02:56<05:53,  8.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0009, 'grad_norm': 0.006174721289426088, 'learning_rate': 6.382978723404256e-06, 'epoch': 36.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 1739/4700 [02:58<03:07, 15.79it/s]\n",
      " 37%|███▋      | 1739/4700 [02:59<03:07, 15.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04421167075634003, 'eval_runtime': 0.0693, 'eval_samples_per_second': 158.726, 'eval_steps_per_second': 86.578, 'epoch': 37.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 1785/4700 [03:03<03:05, 15.72it/s]\n",
      " 38%|███▊      | 1786/4700 [03:03<03:05, 15.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04321393743157387, 'eval_runtime': 0.0707, 'eval_samples_per_second': 155.622, 'eval_steps_per_second': 84.885, 'epoch': 38.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 1803/4700 [03:06<03:52, 12.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0009, 'grad_norm': 0.009139345958828926, 'learning_rate': 6.170212765957447e-06, 'epoch': 38.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 1833/4700 [03:08<03:00, 15.85it/s]\n",
      " 39%|███▉      | 1833/4700 [03:08<03:00, 15.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.040979500859975815, 'eval_runtime': 0.0683, 'eval_samples_per_second': 161.013, 'eval_steps_per_second': 87.825, 'epoch': 39.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 1879/4700 [03:13<03:00, 15.63it/s]\n",
      " 40%|████      | 1880/4700 [03:13<03:00, 15.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.041137970983982086, 'eval_runtime': 0.0703, 'eval_samples_per_second': 156.402, 'eval_steps_per_second': 85.31, 'epoch': 40.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 1903/4700 [03:16<03:13, 14.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0007, 'grad_norm': 0.008595666848123074, 'learning_rate': 5.957446808510638e-06, 'epoch': 40.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 1927/4700 [03:18<02:56, 15.68it/s]\n",
      " 41%|████      | 1927/4700 [03:18<02:56, 15.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0410960428416729, 'eval_runtime': 0.069, 'eval_samples_per_second': 159.341, 'eval_steps_per_second': 86.913, 'epoch': 41.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 1973/4700 [03:23<02:53, 15.70it/s]\n",
      " 42%|████▏     | 1974/4700 [03:23<02:53, 15.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.08654186129570007, 'eval_runtime': 0.0714, 'eval_samples_per_second': 154.045, 'eval_steps_per_second': 84.024, 'epoch': 42.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 2003/4700 [03:26<02:56, 15.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.001, 'grad_norm': 12.814239501953125, 'learning_rate': 5.744680851063831e-06, 'epoch': 42.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 2021/4700 [03:28<02:49, 15.85it/s]\n",
      " 43%|████▎     | 2021/4700 [03:28<02:49, 15.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03966720029711723, 'eval_runtime': 0.0718, 'eval_samples_per_second': 153.306, 'eval_steps_per_second': 83.621, 'epoch': 43.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 2067/4700 [03:32<02:45, 15.93it/s]\n",
      " 44%|████▍     | 2068/4700 [03:32<02:45, 15.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04073072969913483, 'eval_runtime': 0.0698, 'eval_samples_per_second': 157.545, 'eval_steps_per_second': 85.934, 'epoch': 44.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 2103/4700 [03:36<02:48, 15.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.001, 'grad_norm': 0.006541753653436899, 'learning_rate': 5.531914893617022e-06, 'epoch': 44.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 2115/4700 [03:37<02:44, 15.70it/s]\n",
      " 45%|████▌     | 2115/4700 [03:37<02:44, 15.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04037857428193092, 'eval_runtime': 0.0729, 'eval_samples_per_second': 150.876, 'eval_steps_per_second': 82.296, 'epoch': 45.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 2161/4700 [03:42<02:42, 15.63it/s]\n",
      " 46%|████▌     | 2162/4700 [03:42<02:42, 15.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03973280265927315, 'eval_runtime': 0.0688, 'eval_samples_per_second': 159.798, 'eval_steps_per_second': 87.163, 'epoch': 46.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 2203/4700 [03:47<02:39, 15.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0007, 'grad_norm': 0.012191567569971085, 'learning_rate': 5.319148936170213e-06, 'epoch': 46.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 2209/4700 [03:47<02:37, 15.77it/s]\n",
      " 47%|████▋     | 2209/4700 [03:47<02:37, 15.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.039428647607564926, 'eval_runtime': 0.0683, 'eval_samples_per_second': 161.032, 'eval_steps_per_second': 87.835, 'epoch': 47.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 2255/4700 [03:52<02:35, 15.68it/s]\n",
      " 48%|████▊     | 2256/4700 [03:52<02:35, 15.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03906620293855667, 'eval_runtime': 0.0708, 'eval_samples_per_second': 155.308, 'eval_steps_per_second': 84.713, 'epoch': 48.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 2303/4700 [03:57<02:33, 15.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0006, 'grad_norm': 0.004878205247223377, 'learning_rate': 5.106382978723404e-06, 'epoch': 48.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 49%|████▉     | 2303/4700 [03:57<02:33, 15.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.039847519248723984, 'eval_runtime': 0.0741, 'eval_samples_per_second': 148.404, 'eval_steps_per_second': 80.948, 'epoch': 49.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 2349/4700 [04:02<02:29, 15.69it/s]\n",
      " 50%|█████     | 2350/4700 [04:02<02:29, 15.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03975449502468109, 'eval_runtime': 0.0718, 'eval_samples_per_second': 153.251, 'eval_steps_per_second': 83.591, 'epoch': 50.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 2397/4700 [04:07<02:25, 15.82it/s]\n",
      " 51%|█████     | 2397/4700 [04:07<02:25, 15.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03961580619215965, 'eval_runtime': 0.0705, 'eval_samples_per_second': 156.027, 'eval_steps_per_second': 85.106, 'epoch': 51.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 2403/4700 [04:09<07:38,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0006, 'grad_norm': 0.004776547197252512, 'learning_rate': 4.893617021276596e-06, 'epoch': 51.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 2443/4700 [04:12<02:21, 15.99it/s]\n",
      " 52%|█████▏    | 2444/4700 [04:12<02:21, 15.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04075395688414574, 'eval_runtime': 0.0723, 'eval_samples_per_second': 152.236, 'eval_steps_per_second': 83.038, 'epoch': 52.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 2491/4700 [04:16<02:20, 15.73it/s]\n",
      " 53%|█████▎    | 2491/4700 [04:16<02:20, 15.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0409214086830616, 'eval_runtime': 0.0721, 'eval_samples_per_second': 152.652, 'eval_steps_per_second': 83.265, 'epoch': 53.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 2503/4700 [04:19<04:02,  9.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0006, 'grad_norm': 0.03157833218574524, 'learning_rate': 4.680851063829788e-06, 'epoch': 53.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 2537/4700 [04:21<02:15, 15.95it/s]\n",
      " 54%|█████▍    | 2538/4700 [04:21<02:15, 15.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04073750972747803, 'eval_runtime': 0.0734, 'eval_samples_per_second': 149.833, 'eval_steps_per_second': 81.727, 'epoch': 54.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 2585/4700 [04:26<02:12, 15.98it/s]\n",
      " 55%|█████▌    | 2585/4700 [04:26<02:12, 15.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04079408198595047, 'eval_runtime': 0.0698, 'eval_samples_per_second': 157.664, 'eval_steps_per_second': 85.998, 'epoch': 55.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 2603/4700 [04:29<02:45, 12.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0005, 'grad_norm': 0.004593093879520893, 'learning_rate': 4.468085106382979e-06, 'epoch': 55.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 2631/4700 [04:31<02:10, 15.85it/s]\n",
      " 56%|█████▌    | 2632/4700 [04:31<02:10, 15.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04119507223367691, 'eval_runtime': 0.071, 'eval_samples_per_second': 154.847, 'eval_steps_per_second': 84.462, 'epoch': 56.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 2679/4700 [04:36<02:07, 15.84it/s]\n",
      " 57%|█████▋    | 2679/4700 [04:36<02:07, 15.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04164031520485878, 'eval_runtime': 0.0722, 'eval_samples_per_second': 152.436, 'eval_steps_per_second': 83.147, 'epoch': 57.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 2703/4700 [04:39<02:18, 14.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0005, 'grad_norm': 0.006184808444231749, 'learning_rate': 4.255319148936171e-06, 'epoch': 57.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 2725/4700 [04:40<02:05, 15.79it/s]\n",
      " 58%|█████▊    | 2726/4700 [04:41<02:04, 15.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.041382454335689545, 'eval_runtime': 0.0704, 'eval_samples_per_second': 156.199, 'eval_steps_per_second': 85.2, 'epoch': 58.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 2773/4700 [04:45<02:01, 15.86it/s]\n",
      " 59%|█████▉    | 2773/4700 [04:45<02:01, 15.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07791271805763245, 'eval_runtime': 0.0705, 'eval_samples_per_second': 155.934, 'eval_steps_per_second': 85.055, 'epoch': 59.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 2803/4700 [04:49<02:03, 15.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0008, 'grad_norm': 0.0051254937425255775, 'learning_rate': 4.042553191489362e-06, 'epoch': 59.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 2819/4700 [04:50<01:57, 16.05it/s]\n",
      " 60%|██████    | 2820/4700 [04:50<01:57, 16.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0980735793709755, 'eval_runtime': 0.0664, 'eval_samples_per_second': 165.781, 'eval_steps_per_second': 90.426, 'epoch': 60.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 2867/4700 [04:55<01:55, 15.81it/s]\n",
      " 61%|██████    | 2867/4700 [04:55<01:55, 15.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.08582782745361328, 'eval_runtime': 0.0699, 'eval_samples_per_second': 157.307, 'eval_steps_per_second': 85.804, 'epoch': 61.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 2903/4700 [04:59<01:55, 15.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0005, 'grad_norm': 0.006678905803710222, 'learning_rate': 3.8297872340425535e-06, 'epoch': 61.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 2913/4700 [05:00<01:53, 15.69it/s]\n",
      " 62%|██████▏   | 2914/4700 [05:00<01:53, 15.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.08089985698461533, 'eval_runtime': 0.0716, 'eval_samples_per_second': 153.71, 'eval_steps_per_second': 83.842, 'epoch': 62.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 2961/4700 [05:05<01:47, 16.18it/s]\n",
      " 63%|██████▎   | 2961/4700 [05:05<01:47, 16.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04057367518544197, 'eval_runtime': 0.0695, 'eval_samples_per_second': 158.168, 'eval_steps_per_second': 86.274, 'epoch': 63.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 3003/4700 [05:09<01:47, 15.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0026, 'grad_norm': 0.005959679372608662, 'learning_rate': 3.6170212765957453e-06, 'epoch': 63.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 3007/4700 [05:09<01:48, 15.66it/s]\n",
      " 64%|██████▍   | 3008/4700 [05:10<01:48, 15.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0412907637655735, 'eval_runtime': 0.072, 'eval_samples_per_second': 152.746, 'eval_steps_per_second': 83.316, 'epoch': 64.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 3055/4700 [05:14<01:42, 16.01it/s]\n",
      " 65%|██████▌   | 3055/4700 [05:14<01:42, 16.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04202314093708992, 'eval_runtime': 0.0684, 'eval_samples_per_second': 160.843, 'eval_steps_per_second': 87.733, 'epoch': 65.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 3101/4700 [05:19<01:41, 15.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'grad_norm': 0.0037007767241448164, 'learning_rate': 3.4042553191489363e-06, 'epoch': 65.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 66%|██████▌   | 3102/4700 [05:19<01:41, 15.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.042490240186452866, 'eval_runtime': 0.0717, 'eval_samples_per_second': 153.371, 'eval_steps_per_second': 83.657, 'epoch': 66.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 3149/4700 [05:24<01:38, 15.78it/s]\n",
      " 67%|██████▋   | 3149/4700 [05:24<01:38, 15.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04237835481762886, 'eval_runtime': 0.0682, 'eval_samples_per_second': 161.333, 'eval_steps_per_second': 88.0, 'epoch': 67.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 3195/4700 [05:28<01:34, 15.90it/s]\n",
      " 68%|██████▊   | 3196/4700 [05:29<01:34, 15.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04276514798402786, 'eval_runtime': 0.0697, 'eval_samples_per_second': 157.73, 'eval_steps_per_second': 86.034, 'epoch': 68.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 3203/4700 [05:31<03:53,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'grad_norm': 0.005685935262590647, 'learning_rate': 3.191489361702128e-06, 'epoch': 68.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 3243/4700 [05:33<01:31, 16.01it/s]\n",
      " 69%|██████▉   | 3243/4700 [05:33<01:31, 16.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04311457276344299, 'eval_runtime': 0.0674, 'eval_samples_per_second': 163.31, 'eval_steps_per_second': 89.078, 'epoch': 69.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 3289/4700 [05:38<01:29, 15.84it/s]\n",
      " 70%|███████   | 3290/4700 [05:38<01:28, 15.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04326026514172554, 'eval_runtime': 0.071, 'eval_samples_per_second': 154.94, 'eval_steps_per_second': 84.513, 'epoch': 70.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3303/4700 [05:41<02:10, 10.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'grad_norm': 0.005183683708310127, 'learning_rate': 2.978723404255319e-06, 'epoch': 70.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 3337/4700 [05:43<01:26, 15.79it/s]\n",
      " 71%|███████   | 3337/4700 [05:43<01:26, 15.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04323548823595047, 'eval_runtime': 0.0704, 'eval_samples_per_second': 156.236, 'eval_steps_per_second': 85.219, 'epoch': 71.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3383/4700 [05:48<01:23, 15.75it/s]\n",
      " 72%|███████▏  | 3384/4700 [05:48<01:23, 15.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04330157861113548, 'eval_runtime': 0.0706, 'eval_samples_per_second': 155.888, 'eval_steps_per_second': 85.03, 'epoch': 72.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3403/4700 [05:51<01:35, 13.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'grad_norm': 0.03309694305062294, 'learning_rate': 2.765957446808511e-06, 'epoch': 72.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 3431/4700 [05:53<01:19, 15.96it/s]\n",
      " 73%|███████▎  | 3431/4700 [05:53<01:19, 15.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04344433918595314, 'eval_runtime': 0.0684, 'eval_samples_per_second': 160.804, 'eval_steps_per_second': 87.711, 'epoch': 73.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 3477/4700 [05:57<01:18, 15.65it/s]\n",
      " 74%|███████▍  | 3478/4700 [05:57<01:18, 15.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04336690530180931, 'eval_runtime': 0.0738, 'eval_samples_per_second': 149.054, 'eval_steps_per_second': 81.302, 'epoch': 74.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 3503/4700 [06:01<01:21, 14.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'grad_norm': 0.0035168055910617113, 'learning_rate': 2.553191489361702e-06, 'epoch': 74.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3525/4700 [06:03<01:14, 15.83it/s]\n",
      " 75%|███████▌  | 3525/4700 [06:03<01:14, 15.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04339845851063728, 'eval_runtime': 0.0703, 'eval_samples_per_second': 156.548, 'eval_steps_per_second': 85.39, 'epoch': 75.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 3571/4700 [06:07<01:10, 16.00it/s]\n",
      " 76%|███████▌  | 3572/4700 [06:08<01:10, 16.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04351821169257164, 'eval_runtime': 0.0679, 'eval_samples_per_second': 162.035, 'eval_steps_per_second': 88.383, 'epoch': 76.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 3603/4700 [06:12<01:10, 15.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'grad_norm': 0.0033774259500205517, 'learning_rate': 2.340425531914894e-06, 'epoch': 76.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 3619/4700 [06:13<01:06, 16.29it/s]\n",
      " 77%|███████▋  | 3619/4700 [06:13<01:06, 16.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04908238723874092, 'eval_runtime': 0.071, 'eval_samples_per_second': 154.996, 'eval_steps_per_second': 84.543, 'epoch': 77.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 3665/4700 [06:18<01:04, 16.05it/s]\n",
      " 78%|███████▊  | 3666/4700 [06:18<01:04, 16.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.05507812649011612, 'eval_runtime': 0.0719, 'eval_samples_per_second': 153.091, 'eval_steps_per_second': 83.504, 'epoch': 78.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 3703/4700 [06:23<01:04, 15.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'grad_norm': 0.0036171646788716316, 'learning_rate': 2.1276595744680853e-06, 'epoch': 78.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 3713/4700 [06:24<01:02, 15.86it/s]\n",
      " 79%|███████▉  | 3713/4700 [06:24<01:02, 15.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.05383574590086937, 'eval_runtime': 0.0692, 'eval_samples_per_second': 158.916, 'eval_steps_per_second': 86.682, 'epoch': 79.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 3759/4700 [06:30<00:58, 16.06it/s]\n",
      " 80%|████████  | 3760/4700 [06:30<00:58, 16.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.052710842341184616, 'eval_runtime': 0.068, 'eval_samples_per_second': 161.656, 'eval_steps_per_second': 88.176, 'epoch': 80.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 3803/4700 [06:35<00:57, 15.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'grad_norm': 0.004580102860927582, 'learning_rate': 1.9148936170212767e-06, 'epoch': 80.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 3807/4700 [06:35<00:56, 15.84it/s]\n",
      " 81%|████████  | 3807/4700 [06:35<00:56, 15.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.05107694864273071, 'eval_runtime': 0.0697, 'eval_samples_per_second': 157.884, 'eval_steps_per_second': 86.119, 'epoch': 81.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 3853/4700 [06:41<00:53, 15.83it/s]\n",
      " 82%|████████▏ | 3854/4700 [06:41<00:53, 15.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04933178797364235, 'eval_runtime': 0.0732, 'eval_samples_per_second': 150.175, 'eval_steps_per_second': 81.914, 'epoch': 82.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 3901/4700 [06:47<00:49, 16.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'grad_norm': 0.003297780640423298, 'learning_rate': 1.7021276595744682e-06, 'epoch': 82.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 83%|████████▎ | 3901/4700 [06:47<00:49, 16.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.048317547887563705, 'eval_runtime': 0.0724, 'eval_samples_per_second': 151.917, 'eval_steps_per_second': 82.864, 'epoch': 83.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 3947/4700 [06:52<00:46, 16.13it/s]\n",
      " 84%|████████▍ | 3948/4700 [06:53<00:46, 16.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.047324202954769135, 'eval_runtime': 0.0748, 'eval_samples_per_second': 147.055, 'eval_steps_per_second': 80.212, 'epoch': 84.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 3995/4700 [06:57<00:44, 15.85it/s]\n",
      " 85%|████████▌ | 3995/4700 [06:57<00:44, 15.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04655924066901207, 'eval_runtime': 0.0713, 'eval_samples_per_second': 154.227, 'eval_steps_per_second': 84.124, 'epoch': 85.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 4003/4700 [07:00<02:07,  5.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'grad_norm': 0.006560354959219694, 'learning_rate': 1.4893617021276596e-06, 'epoch': 85.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 4041/4700 [07:02<00:41, 16.00it/s]\n",
      " 86%|████████▌ | 4042/4700 [07:03<00:41, 16.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04633384943008423, 'eval_runtime': 0.07, 'eval_samples_per_second': 157.096, 'eval_steps_per_second': 85.689, 'epoch': 86.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 4089/4700 [07:08<00:38, 16.03it/s]\n",
      " 87%|████████▋ | 4089/4700 [07:08<00:38, 16.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04588129371404648, 'eval_runtime': 0.0686, 'eval_samples_per_second': 160.416, 'eval_steps_per_second': 87.5, 'epoch': 87.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 4103/4700 [07:11<00:58, 10.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0003, 'grad_norm': 0.002846543211489916, 'learning_rate': 1.276595744680851e-06, 'epoch': 87.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 4135/4700 [07:13<00:36, 15.60it/s]\n",
      " 88%|████████▊ | 4136/4700 [07:13<00:36, 15.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04580669105052948, 'eval_runtime': 0.0701, 'eval_samples_per_second': 157.013, 'eval_steps_per_second': 85.643, 'epoch': 88.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 4183/4700 [07:18<00:32, 15.71it/s]\n",
      " 89%|████████▉ | 4183/4700 [07:18<00:32, 15.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04526777192950249, 'eval_runtime': 0.0706, 'eval_samples_per_second': 155.745, 'eval_steps_per_second': 84.952, 'epoch': 89.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 4203/4700 [07:21<00:37, 13.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0003, 'grad_norm': 0.003883709665387869, 'learning_rate': 1.0638297872340427e-06, 'epoch': 89.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 4229/4700 [07:23<00:30, 15.65it/s]\n",
      " 90%|█████████ | 4230/4700 [07:23<00:30, 15.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0451212152838707, 'eval_runtime': 0.0714, 'eval_samples_per_second': 154.153, 'eval_steps_per_second': 84.083, 'epoch': 90.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 4277/4700 [07:28<00:26, 15.83it/s]\n",
      " 91%|█████████ | 4277/4700 [07:28<00:26, 15.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04500315710902214, 'eval_runtime': 0.0692, 'eval_samples_per_second': 158.903, 'eval_steps_per_second': 86.674, 'epoch': 91.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 4303/4700 [07:33<00:27, 14.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0003, 'grad_norm': 0.00404032738879323, 'learning_rate': 8.510638297872341e-07, 'epoch': 91.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 4323/4700 [07:34<00:23, 15.80it/s]\n",
      " 92%|█████████▏| 4324/4700 [07:34<00:23, 15.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04486975446343422, 'eval_runtime': 0.0677, 'eval_samples_per_second': 162.381, 'eval_steps_per_second': 88.572, 'epoch': 92.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 4371/4700 [07:39<00:20, 15.72it/s]\n",
      " 93%|█████████▎| 4371/4700 [07:39<00:20, 15.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04472574591636658, 'eval_runtime': 0.0668, 'eval_samples_per_second': 164.656, 'eval_steps_per_second': 89.812, 'epoch': 93.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 4403/4700 [07:44<00:19, 15.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'grad_norm': 0.0026400992646813393, 'learning_rate': 6.382978723404255e-07, 'epoch': 93.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 4417/4700 [07:45<00:18, 15.69it/s]\n",
      " 94%|█████████▍| 4418/4700 [07:45<00:17, 15.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04458744078874588, 'eval_runtime': 0.0704, 'eval_samples_per_second': 156.181, 'eval_steps_per_second': 85.19, 'epoch': 94.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 4465/4700 [07:50<00:14, 15.78it/s]\n",
      " 95%|█████████▌| 4465/4700 [07:50<00:14, 15.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04434718191623688, 'eval_runtime': 0.0693, 'eval_samples_per_second': 158.641, 'eval_steps_per_second': 86.532, 'epoch': 95.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 4503/4700 [07:54<00:12, 15.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0003, 'grad_norm': 0.0029811859130859375, 'learning_rate': 4.2553191489361704e-07, 'epoch': 95.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 4511/4700 [07:55<00:12, 15.56it/s]\n",
      " 96%|█████████▌| 4512/4700 [07:55<00:12, 15.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04419024661183357, 'eval_runtime': 0.0723, 'eval_samples_per_second': 152.191, 'eval_steps_per_second': 83.013, 'epoch': 96.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 4559/4700 [07:59<00:08, 15.80it/s]\n",
      " 97%|█████████▋| 4559/4700 [08:00<00:08, 15.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04489561542868614, 'eval_runtime': 0.0665, 'eval_samples_per_second': 165.309, 'eval_steps_per_second': 90.169, 'epoch': 97.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 4603/4700 [08:04<00:06, 15.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0013, 'grad_norm': 0.003040699288249016, 'learning_rate': 2.1276595744680852e-07, 'epoch': 97.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 4605/4700 [08:04<00:06, 15.69it/s]\n",
      " 98%|█████████▊| 4606/4700 [08:04<00:05, 15.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.045111220329999924, 'eval_runtime': 0.0715, 'eval_samples_per_second': 153.926, 'eval_steps_per_second': 83.96, 'epoch': 98.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 4653/4700 [08:10<00:02, 15.79it/s]\n",
      " 99%|█████████▉| 4653/4700 [08:10<00:02, 15.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04509497061371803, 'eval_runtime': 0.0705, 'eval_samples_per_second': 156.081, 'eval_steps_per_second': 85.135, 'epoch': 99.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4700/4700 [08:15<00:00, 15.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0003, 'grad_norm': 0.003243876388296485, 'learning_rate': 0.0, 'epoch': 100.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4700/4700 [08:17<00:00, 15.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04508901387453079, 'eval_runtime': 0.0302, 'eval_samples_per_second': 364.469, 'eval_steps_per_second': 198.801, 'epoch': 100.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4700/4700 [08:24<00:00,  9.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 504.2092, 'train_samples_per_second': 18.445, 'train_steps_per_second': 9.322, 'train_loss': 0.017546459908022526, 'epoch': 100.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./ner_model/tokenizer_config.json',\n",
       " './ner_model/special_tokens_map.json',\n",
       " './ner_model/vocab.txt',\n",
       " './ner_model/added_tokens.json',\n",
       " './ner_model/tokenizer.json')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast, BertForTokenClassification, TrainingArguments, Trainer\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize tokenizer\n",
    "# tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('./data/ner_data.csv')\n",
    "\n",
    "# Convert stringified lists in 'labels' to actual lists\n",
    "data[\"labels\"] = data[\"labels\"].apply(eval)\n",
    "\n",
    "# Extract unique labels and create a mapping\n",
    "unique_labels = sorted({label for labels in data[\"labels\"] for label in labels})\n",
    "\n",
    "# unique_labels = ['B-ORD', 'I-ORD', 'O']\n",
    "label_to_id = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "id_to_label = {idx: label for label, idx in label_to_id.items()}\n",
    "\n",
    "print(\"Label to ID Mapping:\", label_to_id)\n",
    "\n",
    "# Convert DataFrame to list of dictionaries\n",
    "data_dict = data.to_dict(orient=\"records\")\n",
    "\n",
    "\n",
    "# Tokenize and align labels\n",
    "\n",
    "# Convert data to Hugging Face Dataset\n",
    "hf_dataset = Dataset.from_list(data_dict)\n",
    "\n",
    "# Split the dataset into train and validation sets\n",
    "train_data, val_data = train_test_split(data_dict, test_size=0.1, random_state=42)\n",
    "hf_dataset = DatasetDict({\n",
    "    \"train\": Dataset.from_list(train_data),\n",
    "    \"validation\": Dataset.from_list(val_data),\n",
    "})\n",
    "\n",
    "# Apply the tokenizer and label alignment\n",
    "hf_dataset = hf_dataset.map(tokenize_and_align_labels, batched=False)\n",
    "# Define the model\n",
    "model = BertForTokenClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=len(label_to_id),\n",
    "    id2label=id_to_label,\n",
    "    label2id=label_to_id\n",
    ")\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer)) # need to test\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./ner_model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=1e-5,  # Lower the learning rate to 1e-5\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=100,\n",
    "    weight_decay=0.0001,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "\n",
    "# Use default data collator for token classification\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "# Define the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=hf_dataset[\"train\"],\n",
    "    eval_dataset=hf_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the model and tokenizer\n",
    "model.save_pretrained(\"./ner_model\")\n",
    "tokenizer.save_pretrained(\"./ner_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted entity: [('END_DATE', ['november44']), ('START_DATE', ['21', '202', '10', 'april', '202'])]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast, BertForTokenClassification\n",
    "import torch\n",
    "\n",
    "# Load the saved model and tokenizer\n",
    "# model_dir = \"./ner_model\"\n",
    "# tokenizer = BertTokenizerFast.from_pretrained(model_dir)\n",
    "# model = BertForTokenClassification.from_pretrained(model_dir)\n",
    "\n",
    "# Load the label mappings\n",
    "id_to_label = model.config.id2label\n",
    "\n",
    "# Sample text to test the model\n",
    "test_sentences = [\n",
    "    \"[INT] [BOT]  [USR] Order 121435, whats the status?\"\n",
    "]\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def predict_ner(sentence):\n",
    "    # Tokenize the sentence\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True, max_length=128).to(device)\n",
    "    # print(inputs)\n",
    "\n",
    "    # Get model predictions\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Extract logits and compute predictions\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=2)\n",
    "\n",
    "    # Map predictions to labels\n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "    predicted_labels = [id_to_label[pred.item()] for pred in predictions[0]]\n",
    "\n",
    "    # Combine tokens and predicted labels\n",
    "    results = []\n",
    "    for token, label in zip(tokens, predicted_labels):\n",
    "        if token not in [\"[CLS]\", \"[SEP]\", \"[PAD]\"]:  # Ignore special tokens\n",
    "            results.append((token, label))\n",
    "    return results\n",
    "\n",
    "# Test the model with sample sentences\n",
    "for sentence in test_sentences:\n",
    "    # print(f\"Sentence: {sentence}\")\n",
    "    predictions = predict_ner(sentence)\n",
    "    # print(\"Predictions:\")\n",
    "    # for token, label in predictions:\n",
    "        # print(f\"{token:15} -> {label}\")\n",
    "    # print(\"\\n\")\n",
    "\n",
    "def extract_entity(sentence, entity_label):\n",
    "    \"\"\"\n",
    "    enitity_label: the label of the entity to extract (ORD for example)\n",
    "    extract the entity from the sentence along with I-ORD tokens\n",
    "    \"\"\"\n",
    "    # Get NER predictions\n",
    "    predictions = predict_ner(sentence)\n",
    "    # for token, label in predictions:\n",
    "    #     # print(f\"{token:15} -> {label}\")\n",
    "\n",
    "    # get all entities in the label\n",
    "    all_entities = []\n",
    "    for token, label in predictions:\n",
    "        if label.startswith(\"B-\") or label.startswith(\"I-\"):\n",
    "            all_entities.append(label.split(\"-\")[1])\n",
    "\n",
    "    all_entities = list(set(all_entities))\n",
    "\n",
    "    return_values = []\n",
    "    for entity_label in all_entities:\n",
    "        # Extract entities with the specified label\n",
    "        entities = []\n",
    "        for token, label in predictions:\n",
    "            if label == f\"B-{entity_label}\" or label == f\"I-{entity_label}\":\n",
    "                entities.append(token)\n",
    "        # print(entities)\n",
    "        \n",
    "        # remove subword prefixes from the entities\n",
    "        entity_combined = []\n",
    "        prev_entity = None\n",
    "        for i , entity in enumerate(entities):\n",
    "            if entity.startswith(\"##\"):\n",
    "                if prev_entity is None:\n",
    "                    prev_entity = \"\"\n",
    "                prev_entity += entity[2:]\n",
    "            else:\n",
    "                if prev_entity:\n",
    "                    entity_combined.append(prev_entity)\n",
    "                prev_entity = entity\n",
    "\n",
    "            if i == len(entities) - 1:\n",
    "                entity_combined.append(prev_entity)\n",
    "        return_values.append((entity_label, entity_combined))\n",
    "    return return_values\n",
    "        \n",
    "\n",
    "# get the B-COUNT entity from the sentence\n",
    "sentence = \"[INT] [BOT]  [USR] Please show me a list of all the orders I've made before 21 November 2024 and after 10 April 2024\"\n",
    "entity_label = \"START_DATE\"\n",
    "extracted_entity = extract_entity(sentence, entity_label)\n",
    "print(f\"Extracted entity: {extracted_entity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: [INT] [BOT]  [USR] Can you check my order 12345?\n",
      "Extracted entity: [('ORD', ['12345'])]\n",
      "\n",
      "Sentence: [INT] cancel_order [BOT] Please confirm the cancellation of your last order. [USR] Yes, confirm it.\n",
      "Extracted entity: [('AFFIRMATION', ['yes'])]\n",
      "\n",
      "Sentence: [INT] [BOT]  [USR] Cancel the last item I ordered.\n",
      "Extracted entity: [('ORD', ['last'])]\n",
      "\n",
      "Sentence: [INT] give_order_id [BOT] Are you sure? [USR] Yes I am sure!\n",
      "Extracted entity: [('AFFIRMATION', ['yes'])]\n",
      "\n",
      "Sentence: [INT] list_orders [BOT] Do you need to filter anything? [USR] Yeah give me just 32 of them\n",
      "Extracted entity: [('COUNT', ['32'])]\n",
      "\n",
      "Sentence: [INT] cancel_order [BOT] Can you confirm the cancellation of your most recent order? [USR] No, don’t proceed with it.\n",
      "Extracted entity: [('AFFIRMATION', ['no'])]\n",
      "\n",
      "Sentence: [INT] cancel_order [BOT] Are you sure you want to cancel order 112233? [USR] No, leave it as is.\n",
      "Extracted entity: [('AFFIRMATION', ['no'])]\n",
      "\n",
      "Sentence: [INT] [BOT]  [USR] Can you list some of my previous orders?\n",
      "Extracted entity: []\n",
      "\n",
      "Sentence: [INT] track_order [BOT] For which order would you like an update? [USR] Order ID is 5643.\n",
      "Extracted entity: [('ORD', ['5643'])]\n",
      "\n",
      "Sentence: [INT] [BOT]  [USR] Hey can i get the status of my latest order?\n",
      "Extracted entity: []\n",
      "\n",
      "Sentence: [INT] track_order [BOT] Please provide your order number. [USR] It’s 23456.\n",
      "Extracted entity: [('ORD', ['23456'])]\n",
      "\n",
      "Sentence: [INT] [BOT]  [USR] I was wondering where my 121243 order is?\n",
      "Extracted entity: [('ORD', ['order'])]\n",
      "\n",
      "Sentence: [INT] [BOT]  [USR] Please cancel my latest order.\n",
      "Extracted entity: [('ORD', ['latest'])]\n",
      "\n",
      "Sentence: [INT] cancel_order [BOT] Can you confirm that you’d like to cancel order 776655? [USR] No, I’d like to keep it.\n",
      "Extracted entity: [('AFFIRMATION', ['no'])]\n",
      "\n",
      "Sentence: [INT] cancel_order [BOT] Could you confirm cancellation of order number 998877? [USR] Yes, please cancel it.\n",
      "Extracted entity: [('AFFIRMATION', ['yes'])]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test for 15 random samples\n",
    "data = pd.read_csv('./data/ner_data.csv')\n",
    "\n",
    "# draw 15 random samples\n",
    "test_data = data.sample(15)\n",
    "\n",
    "for idx, row in test_data.iterrows():\n",
    "    print(f\"Sentence: {row['instruction']}\")\n",
    "    # get the \n",
    "    extracted_entity = extract_entity(row['instruction'], \"ORD\")\n",
    "    print(f\"Extracted entity: {extracted_entity}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

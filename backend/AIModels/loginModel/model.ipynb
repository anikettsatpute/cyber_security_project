{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Login Pattern Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = \"../../logs/login.json\"\n",
    "file = \"./data/logins_data.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot set a DataFrame with multiple columns to the single column failed_moving_avg_5min",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_49367/2828576052.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Create rolling mean for failed logins based on time intervals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# First, let's assume 5 minutes corresponds to a window of 5 rows, and 10 days corresponds to 10 rows (this can be adjusted based on the actual time differences)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'failed_moving_avg_5min'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'status'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrolling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_periods\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'failed_moving_avg_10days'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'status'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrolling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_periods\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Resetting index to handle rolling operations based on 'ip_address' and prevent duplicate label issues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/IITH/Sem7/CyberSecurityAndAI/project/cyber_security_project/venv/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4297\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4298\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4299\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4300\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4301\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item_frame_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4302\u001b[0m         elif (\n\u001b[1;32m   4303\u001b[0m             \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4304\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/IITH/Sem7/CyberSecurityAndAI/project/cyber_security_project/venv/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4456\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4458\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4459\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   4460\u001b[0m                 \u001b[0;34m\"Cannot set a DataFrame with multiple columns to the single \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4461\u001b[0m                 \u001b[0;34mf\"\u001b[0m\u001b[0;34mcolumn \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4462\u001b[0m             \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot set a DataFrame with multiple columns to the single column failed_moving_avg_5min"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data (your example)\n",
    "data = pd.read_json(file)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Filter out rows older than 10 days\n",
    "# Convert to UTC (if it's already aware and in a different timezone)\n",
    "df['timestamp'] = df['timestamp'].dt.tz_convert('UTC')\n",
    "\n",
    "# Make the current timestamp timezone-aware in UTC\n",
    "df = df[df['timestamp'] > pd.Timestamp.now(tz='UTC') - pd.DateOffset(days=10)]\n",
    "\n",
    "# Set timestamp as index for time-based operations\n",
    "df.set_index('timestamp', inplace=True)\n",
    "\n",
    "# Create rolling mean for failed logins based on time intervals\n",
    "# First, let's assume 5 minutes corresponds to a window of 5 rows, and 10 days corresponds to 10 rows (this can be adjusted based on the actual time differences)\n",
    "df['failed_moving_avg_5min'] = df.groupby('user_id')['status'].rolling(5, min_periods=1).mean().reset_index(level=0, drop=False)\n",
    "df['failed_moving_avg_10days'] = df.groupby('user_id')['status'].rolling(10, min_periods=1).mean().reset_index(level=0, drop=False)\n",
    "\n",
    "# Resetting index to handle rolling operations based on 'ip_address' and prevent duplicate label issues\n",
    "df['failed_moving_avg_5min_ip'] = df.groupby('ip_address')['status'].rolling(5, min_periods=1).mean().reset_index(level=0, drop=False)['status']\n",
    "df['failed_moving_avg_10days_ip'] = df.groupby('ip_address')['status'].rolling(10, min_periods=1).mean().reset_index(level=0, drop=False)['status']\n",
    "\n",
    "# Display the result\n",
    "print(df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    user_id   ip_address  failed_moving_avg_5min_ip  \\\n",
      "timestamp                                                             \n",
      "2024-11-22 00:00:00   user1  192.168.1.1                   1.000000   \n",
      "2024-11-22 00:01:00   user1  192.168.1.1                   1.000000   \n",
      "2024-11-22 00:02:00   user2  192.168.1.2                   1.000000   \n",
      "2024-11-22 00:03:00   user1  192.168.1.1                   0.666667   \n",
      "2024-11-22 00:04:00   user3  192.168.1.3                   1.000000   \n",
      "2024-11-22 00:05:00   user2  192.168.1.2                   0.500000   \n",
      "2024-11-22 00:06:00   user1  192.168.1.1                   0.750000   \n",
      "2024-11-22 00:07:00   user3  192.168.1.3                   0.500000   \n",
      "2024-11-22 00:08:00   user4  192.168.1.4                   0.000000   \n",
      "2024-11-22 00:09:00   user1  192.168.1.1                   0.800000   \n",
      "2024-11-22 00:10:00   user2  192.168.1.2                   0.666667   \n",
      "2024-11-22 00:11:00   user1  192.168.1.1                   0.800000   \n",
      "2024-11-22 00:12:00   user3  192.168.1.3                   0.333333   \n",
      "2024-11-22 00:13:00   user4  192.168.1.4                   0.500000   \n",
      "2024-11-22 00:14:00   user2  192.168.1.2                   0.750000   \n",
      "2024-11-22 00:15:00   user1  192.168.1.1                   0.600000   \n",
      "2024-11-22 00:16:00   user3  192.168.1.3                   0.250000   \n",
      "2024-11-22 00:17:00   user4  192.168.1.4                   0.333333   \n",
      "2024-11-22 00:18:00   user2  192.168.1.2                   0.800000   \n",
      "2024-11-22 00:19:00   user3  192.168.1.3                   0.400000   \n",
      "\n",
      "                     failed_moving_avg_10days_ip  failed_moving_avg_5min  \\\n",
      "timestamp                                                                  \n",
      "2024-11-22 00:00:00                     1.000000                1.000000   \n",
      "2024-11-22 00:01:00                     1.000000                1.000000   \n",
      "2024-11-22 00:02:00                     1.000000                1.000000   \n",
      "2024-11-22 00:03:00                     0.666667                0.666667   \n",
      "2024-11-22 00:04:00                     1.000000                1.000000   \n",
      "2024-11-22 00:05:00                     0.500000                0.500000   \n",
      "2024-11-22 00:06:00                     0.750000                0.750000   \n",
      "2024-11-22 00:07:00                     0.500000                0.500000   \n",
      "2024-11-22 00:08:00                     0.000000                0.000000   \n",
      "2024-11-22 00:09:00                     0.800000                0.800000   \n",
      "2024-11-22 00:10:00                     0.666667                0.666667   \n",
      "2024-11-22 00:11:00                     0.833333                0.800000   \n",
      "2024-11-22 00:12:00                     0.333333                0.333333   \n",
      "2024-11-22 00:13:00                     0.500000                0.500000   \n",
      "2024-11-22 00:14:00                     0.750000                0.750000   \n",
      "2024-11-22 00:15:00                     0.714286                0.600000   \n",
      "2024-11-22 00:16:00                     0.250000                0.250000   \n",
      "2024-11-22 00:17:00                     0.333333                0.333333   \n",
      "2024-11-22 00:18:00                     0.800000                0.800000   \n",
      "2024-11-22 00:19:00                     0.400000                0.400000   \n",
      "\n",
      "                     failed_moving_avg_10days  anomaly  \n",
      "timestamp                                               \n",
      "2024-11-22 00:00:00                  1.000000   Normal  \n",
      "2024-11-22 00:01:00                  1.000000   Normal  \n",
      "2024-11-22 00:02:00                  1.000000   Normal  \n",
      "2024-11-22 00:03:00                  0.666667   Normal  \n",
      "2024-11-22 00:04:00                  1.000000   Normal  \n",
      "2024-11-22 00:05:00                  0.500000   Normal  \n",
      "2024-11-22 00:06:00                  0.750000   Normal  \n",
      "2024-11-22 00:07:00                  0.500000   Normal  \n",
      "2024-11-22 00:08:00                  0.000000  Anomaly  \n",
      "2024-11-22 00:09:00                  0.800000   Normal  \n",
      "2024-11-22 00:10:00                  0.666667   Normal  \n",
      "2024-11-22 00:11:00                  0.833333   Normal  \n",
      "2024-11-22 00:12:00                  0.333333   Normal  \n",
      "2024-11-22 00:13:00                  0.500000   Normal  \n",
      "2024-11-22 00:14:00                  0.750000   Normal  \n",
      "2024-11-22 00:15:00                  0.714286   Normal  \n",
      "2024-11-22 00:16:00                  0.250000  Anomaly  \n",
      "2024-11-22 00:17:00                  0.333333   Normal  \n",
      "2024-11-22 00:18:00                  0.800000   Normal  \n",
      "2024-11-22 00:19:00                  0.400000   Normal  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Select features for the Isolation Forest model\n",
    "features = ['failed_moving_avg_5min', 'failed_moving_avg_10days', 'failed_moving_avg_5min_ip', 'failed_moving_avg_10days_ip']\n",
    "X = df[features]\n",
    "\n",
    "# Initialize Isolation Forest model\n",
    "iso_forest = IsolationForest(contamination=0.1)  # You can adjust the contamination parameter\n",
    "\n",
    "# Fit the model\n",
    "df['anomaly'] = iso_forest.fit_predict(X)\n",
    "\n",
    "# The anomaly column will have values of 1 for normal data points and -1 for anomalies\n",
    "# Convert -1 to 'Anomaly' and 1 to 'Normal'\n",
    "df['anomaly'] = df['anomaly'].map({1: 'Normal', -1: 'Anomaly'})\n",
    "\n",
    "# Also give anomaly score between 0 and 1\n",
    "df['anomaly_score'] = iso_forest.decision_function(X)\n",
    "\n",
    "# Display the anomalies with score greater than 0.5\n",
    "print(df[df['anomaly_score'] > 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    user_id   ip_address  failed  failed_moving_avg_5min  \\\n",
      "timestamp                                                                  \n",
      "2024-11-22 00:00:00   user1  192.168.1.1       1                1.000000   \n",
      "2024-11-22 00:01:00   user1  192.168.1.1       1                1.000000   \n",
      "2024-11-22 00:02:00   user2  192.168.1.2       1                1.000000   \n",
      "2024-11-22 00:03:00   user1  192.168.1.1       0                0.666667   \n",
      "2024-11-22 00:04:00   user3  192.168.1.3       1                1.000000   \n",
      "2024-11-22 00:05:00   user2  192.168.1.2       0                0.500000   \n",
      "2024-11-22 00:06:00   user1  192.168.1.1       1                0.750000   \n",
      "2024-11-22 00:07:00   user3  192.168.1.3       0                0.500000   \n",
      "2024-11-22 00:08:00   user4  192.168.1.4       0                0.000000   \n",
      "2024-11-22 00:09:00   user1  192.168.1.1       1                0.800000   \n",
      "2024-11-22 00:10:00   user2  192.168.1.2       1                0.666667   \n",
      "2024-11-22 00:11:00   user1  192.168.1.1       1                0.800000   \n",
      "2024-11-22 00:12:00   user3  192.168.1.3       0                0.333333   \n",
      "2024-11-22 00:13:00   user4  192.168.1.4       1                0.500000   \n",
      "2024-11-22 00:14:00   user2  192.168.1.2       1                0.750000   \n",
      "2024-11-22 00:15:00   user1  192.168.1.1       0                0.600000   \n",
      "2024-11-22 00:16:00   user3  192.168.1.3       0                0.250000   \n",
      "2024-11-22 00:17:00   user4  192.168.1.4       0                0.333333   \n",
      "2024-11-22 00:18:00   user2  192.168.1.2       1                0.800000   \n",
      "2024-11-22 00:19:00   user3  192.168.1.3       1                0.400000   \n",
      "\n",
      "                     failed_moving_avg_10days  anomaly device_type       OS  \\\n",
      "timestamp                                                                     \n",
      "2024-11-22 00:00:00                  1.000000   Normal     Desktop    Linux   \n",
      "2024-11-22 00:01:00                  1.000000  Anomaly      Mobile  Windows   \n",
      "2024-11-22 00:02:00                  1.000000   Normal     Desktop    Linux   \n",
      "2024-11-22 00:03:00                  0.666667   Normal      Mobile  Windows   \n",
      "2024-11-22 00:04:00                  1.000000   Normal     Desktop    Linux   \n",
      "2024-11-22 00:05:00                  0.500000   Normal      Mobile  Windows   \n",
      "2024-11-22 00:06:00                  0.750000   Normal     Desktop    Linux   \n",
      "2024-11-22 00:07:00                  0.500000   Normal     Desktop    Linux   \n",
      "2024-11-22 00:08:00                  0.000000  Anomaly      Mobile  Windows   \n",
      "2024-11-22 00:09:00                  0.800000   Normal     Desktop    Linux   \n",
      "2024-11-22 00:10:00                  0.666667   Normal     Desktop  Windows   \n",
      "2024-11-22 00:11:00                  0.833333   Normal      Mobile    Linux   \n",
      "2024-11-22 00:12:00                  0.333333   Normal     Desktop  Windows   \n",
      "2024-11-22 00:13:00                  0.500000   Normal      Mobile    Linux   \n",
      "2024-11-22 00:14:00                  0.750000   Normal     Desktop  Windows   \n",
      "2024-11-22 00:15:00                  0.714286   Normal      Mobile    Linux   \n",
      "2024-11-22 00:16:00                  0.250000   Normal     Desktop  Windows   \n",
      "2024-11-22 00:17:00                  0.333333   Normal      Mobile    Linux   \n",
      "2024-11-22 00:18:00                  0.800000   Normal     Desktop  Windows   \n",
      "2024-11-22 00:19:00                  0.400000   Normal      Mobile    Linux   \n",
      "\n",
      "                     browser  \n",
      "timestamp                     \n",
      "2024-11-22 00:00:00   Chrome  \n",
      "2024-11-22 00:01:00  Firefox  \n",
      "2024-11-22 00:02:00   Chrome  \n",
      "2024-11-22 00:03:00  Firefox  \n",
      "2024-11-22 00:04:00   Chrome  \n",
      "2024-11-22 00:05:00  Firefox  \n",
      "2024-11-22 00:06:00   Chrome  \n",
      "2024-11-22 00:07:00   Chrome  \n",
      "2024-11-22 00:08:00  Firefox  \n",
      "2024-11-22 00:09:00   Chrome  \n",
      "2024-11-22 00:10:00  Firefox  \n",
      "2024-11-22 00:11:00   Chrome  \n",
      "2024-11-22 00:12:00  Firefox  \n",
      "2024-11-22 00:13:00   Chrome  \n",
      "2024-11-22 00:14:00  Firefox  \n",
      "2024-11-22 00:15:00   Chrome  \n",
      "2024-11-22 00:16:00  Firefox  \n",
      "2024-11-22 00:17:00   Chrome  \n",
      "2024-11-22 00:18:00  Firefox  \n",
      "2024-11-22 00:19:00   Chrome  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_44843/9674719.py:6: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  'timestamp': pd.date_range(start='2024-11-22', periods=20, freq='T'),\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Sample data (including new features)\n",
    "data = {\n",
    "    'timestamp': pd.date_range(start='2024-11-22', periods=20, freq='T'),\n",
    "    'user_id': ['user1', 'user1', 'user2', 'user1', 'user3', 'user2', 'user1', 'user3', 'user4', 'user1', 'user2', 'user1', 'user3', 'user4', 'user2', 'user1', 'user3', 'user4', 'user2', 'user3'],\n",
    "    'ip_address': ['192.168.1.1', '192.168.1.1', '192.168.1.2', '192.168.1.1', '192.168.1.3', '192.168.1.2', '192.168.1.1', '192.168.1.3', '192.168.1.4', '192.168.1.1', '192.168.1.2', '192.168.1.1', '192.168.1.3', '192.168.1.4', '192.168.1.2', '192.168.1.1', '192.168.1.3', '192.168.1.4', '192.168.1.2', '192.168.1.3'],\n",
    "    'failed': [1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1],\n",
    "    'device_type': ['Desktop', 'Mobile', 'Desktop', 'Mobile', 'Desktop', 'Mobile', 'Desktop', 'Desktop', 'Mobile', 'Desktop', 'Desktop', 'Mobile', 'Desktop', 'Mobile', 'Desktop', 'Mobile', 'Desktop', 'Mobile', 'Desktop', 'Mobile'],\n",
    "    'OS': ['Linux', 'Windows', 'Linux', 'Windows', 'Linux', 'Windows', 'Linux', 'Linux', 'Windows', 'Linux', 'Windows', 'Linux', 'Windows', 'Linux', 'Windows', 'Linux', 'Windows', 'Linux', 'Windows', 'Linux'],\n",
    "    'browser': ['Chrome', 'Firefox', 'Chrome', 'Firefox', 'Chrome', 'Firefox', 'Chrome', 'Chrome', 'Firefox', 'Chrome', 'Firefox', 'Chrome', 'Firefox', 'Chrome', 'Firefox', 'Chrome', 'Firefox', 'Chrome', 'Firefox', 'Chrome']\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Filter out rows older than 10 days\n",
    "df = df[df['timestamp'] > pd.Timestamp.now() - pd.DateOffset(days=10)]\n",
    "\n",
    "# Set timestamp as index for time-based operations\n",
    "df.set_index('timestamp', inplace=True)\n",
    "\n",
    "# Create rolling mean for failed logins based on time intervals\n",
    "df['failed_moving_avg_5min'] = df.groupby('user_id')['failed'].rolling(5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "df['failed_moving_avg_10days'] = df.groupby('user_id')['failed'].rolling(10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "\n",
    "df['failed_moving_avg_5min_ip'] = df.groupby('ip_address')['failed'].rolling(5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "df['failed_moving_avg_10days_ip'] = df.groupby('ip_address')['failed'].rolling(10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "\n",
    "# One-Hot Encoding for categorical columns (device_type, OS, browser)\n",
    "df_encoded = pd.get_dummies(df[['device_type', 'OS', 'browser']], drop_first=True)\n",
    "\n",
    "# Combine the encoded features with the existing numerical features\n",
    "features = [\n",
    "    'failed_moving_avg_5min', 'failed_moving_avg_10days', 'failed_moving_avg_5min_ip', 'failed_moving_avg_10days_ip'\n",
    "]\n",
    "\n",
    "# Include categorical features directly in the features list\n",
    "X = pd.concat([df[features], df_encoded], axis=1)\n",
    "\n",
    "# Initialize Isolation Forest model\n",
    "iso_forest = IsolationForest(contamination=0.1)  # You can adjust the contamination parameter\n",
    "\n",
    "# Fit the model\n",
    "df['anomaly'] = iso_forest.fit_predict(X)\n",
    "\n",
    "# The anomaly column will have values of 1 for normal data points and -1 for anomalies\n",
    "# Convert -1 to 'Anomaly' and 1 to 'Normal'\n",
    "df['anomaly'] = df['anomaly'].map({1: 'Normal', -1: 'Anomaly'})\n",
    "\n",
    "# Display the results\n",
    "print(df[['user_id', 'ip_address', 'failed', 'failed_moving_avg_5min', 'failed_moving_avg_10days', 'anomaly', 'device_type', 'OS', 'browser']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

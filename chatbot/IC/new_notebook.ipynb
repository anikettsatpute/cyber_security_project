{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INT] track_order [BOT] Can you please share the order number so I can check? [USR] It's 98765.\n"
     ]
    }
   ],
   "source": [
    "# Sample dialogue data\n",
    "dialogue = {\n",
    "    \"dialogue_id\": 13,\n",
    "    \"turns\": [\n",
    "        {\n",
    "            \"speaker\": \"User\",\n",
    "            \"text\": \"Where is my package? I need to track it.\",\n",
    "            \"intent\": \"track_order\",\n",
    "            \"entities\": []\n",
    "        },\n",
    "        {\n",
    "            \"speaker\": \"Bot\",\n",
    "            \"text\": \"Can you please share the order number so I can check?\"\n",
    "        },\n",
    "        {\n",
    "            \"speaker\": \"User\",\n",
    "            \"text\": \"It's 98765.\",\n",
    "            \"intent\": \"give_order_id\",\n",
    "            \"entities\": [\n",
    "                {\n",
    "                    \"entity\": \"98765\",\n",
    "                    \"type\": \"order_number\",\n",
    "                    \"start\": 5,\n",
    "                    \"end\": 10\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "entity_labels = {\n",
    "    \"order_number\": \"ORDER_NUMBER\"\n",
    "}\n",
    "\n",
    "def create_bert_input(dialogue):\n",
    "    # Initialize the previous intent (for the first turn, it's empty)\n",
    "    previous_intent = None\n",
    "    bot_response = None\n",
    "    bert_input = []\n",
    "    \n",
    "    # Loop through each turn to format the state\n",
    "    for turn in dialogue[\"turns\"]:\n",
    "        speaker = turn[\"speaker\"]\n",
    "        text = turn[\"text\"]\n",
    "        \n",
    "        if speaker == \"User\":\n",
    "            # Concatenate the dialogue for User's query and Bot's response\n",
    "            if previous_intent is not None and bot_response is not None:\n",
    "                # Create the formatted string for the previous intent, bot response, and user query\n",
    "                state_input = f\"[INT] {previous_intent} [BOT] {bot_response} [USR] {text}\"\n",
    "                bert_input.append(state_input)\n",
    "            # Update the previous intent with the current turn's intent\n",
    "            previous_intent = turn[\"intent\"]\n",
    "        \n",
    "        elif speaker == \"Bot\":\n",
    "            # Save the bot response to include it in the next user query\n",
    "            bot_response = text\n",
    "    \n",
    "    return bert_input\n",
    "\n",
    "# Get the formatted BERT input\n",
    "bert_input = create_bert_input(dialogue)\n",
    "\n",
    "# Print the resulting list of inputs for BERT\n",
    "for input_str in bert_input:\n",
    "    print(input_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data point 1: [INT] [BOT]  [USR] Where is my package? I need to track it.\n",
      "Data point 2: [INT] track_order [BOT] Can you please share the order number so I can check? [USR] It's 98765.\n"
     ]
    }
   ],
   "source": [
    "# Sample dialogue data\n",
    "dialogue = {\n",
    "    \"dialogue_id\": 13,\n",
    "    \"turns\": [\n",
    "        {\n",
    "            \"speaker\": \"User\",\n",
    "            \"text\": \"Where is my package? I need to track it.\",\n",
    "            \"intent\": \"track_order\",\n",
    "            \"entities\": []\n",
    "        },\n",
    "        {\n",
    "            \"speaker\": \"Bot\",\n",
    "            \"text\": \"Can you please share the order number so I can check?\"\n",
    "        },\n",
    "        {\n",
    "            \"speaker\": \"User\",\n",
    "            \"text\": \"It's 98765.\",\n",
    "            \"intent\": \"give_order_id\",\n",
    "            \"entities\": [\n",
    "                {\n",
    "                    \"entity\": \"98765\",\n",
    "                    \"type\": \"order_number\",\n",
    "                    \"start\": 5,\n",
    "                    \"end\": 10\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "def create_bert_input_split(dialogue):\n",
    "    previous_intent = None\n",
    "    bot_response = None\n",
    "    bert_input = []\n",
    "    labels = []\n",
    "\n",
    "    # First, create the first data point (without previous intent)\n",
    "    first_turn = dialogue[\"turns\"][0]  # The first user query\n",
    "    first_user_query = first_turn[\"text\"]\n",
    "    \n",
    "    # Create the first data point with the user query and the bot response\n",
    "    first_data_point = f\"[INT] [BOT] {bot_response or ''} [USR] {first_user_query}\"\n",
    "    bert_input.append(first_data_point)\n",
    "    \n",
    "    # Now, process the second data point\n",
    "    for i, turn in enumerate(dialogue[\"turns\"]):\n",
    "        if turn[\"speaker\"] == \"User\":\n",
    "            user_query = turn[\"text\"]\n",
    "            if previous_intent is not None and bot_response is not None:\n",
    "                # Create the second data point with the previous intent, bot response, and user query\n",
    "                second_data_point = f\"[INT] {previous_intent} [BOT] {bot_response} [USR] {user_query}\"\n",
    "                bert_input.append(second_data_point)\n",
    "                labels.append(turn[\"intent\"])\n",
    "        elif turn[\"speaker\"] == \"Bot\":\n",
    "            # Save the bot response for the second data point\n",
    "            bot_response = turn[\"text\"]\n",
    "        \n",
    "        # Update the previous intent\n",
    "        if turn[\"speaker\"] == \"User\":\n",
    "            previous_intent = turn[\"intent\"]\n",
    "\n",
    "    return bert_input, labels\n",
    "\n",
    "# Get the formatted BERT input (split into data points)\n",
    "bert_input, labels = create_bert_input_split(dialogue)\n",
    "\n",
    "# Print the resulting list of inputs for BERT\n",
    "for i, input_str in enumerate(bert_input):\n",
    "    print(f\"Data point {i + 1}: {input_str}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[INT] [BOT]  [USR] Where is my package? I need to track it.', \"[INT] track_order [BOT] Can you please share the order number so I can check? [USR] It's 98765.\"]\n"
     ]
    }
   ],
   "source": [
    "print(bert_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Sample dataset file (replace with your actual file path)\n",
    "data_file = '../data/dialogues_fixed.json'\n",
    "\n",
    "def create_bert_input_split(dialogue):\n",
    "    previous_intent = None\n",
    "    bot_response = None\n",
    "    bert_input = []\n",
    "    labels = []\n",
    "    entities = []\n",
    "    \n",
    "    # Process the first turn to create the first data point\n",
    "    first_turn = dialogue[\"turns\"][0]  # First user query\n",
    "    first_user_query = first_turn[\"text\"]\n",
    "    \n",
    "    # Create the first data point (without previous intent)\n",
    "    first_data_point = f\"[INT] [BOT] {bot_response or ''} [USR] {first_user_query}\"\n",
    "    labels.append(first_turn[\"intent\"])\n",
    "    entities.append(first_turn[\"entities\"])\n",
    "    bert_input.append(first_data_point)\n",
    "    \n",
    "    # Process the rest of the turns\n",
    "    for i, turn in enumerate(dialogue[\"turns\"]):\n",
    "        if turn[\"speaker\"] == \"User\":\n",
    "            user_query = turn[\"text\"]\n",
    "            if previous_intent is not None and bot_response is not None:\n",
    "                # Create the subsequent data point with the previous intent and bot response\n",
    "                second_data_point = f\"[INT] {previous_intent} [BOT] {bot_response} [USR] {user_query}\"\n",
    "                bert_input.append(second_data_point)\n",
    "                labels.append(turn[\"intent\"])\n",
    "        elif turn[\"speaker\"] == \"Bot\":\n",
    "            # Capture the bot response\n",
    "            bot_response = turn[\"text\"]\n",
    "        \n",
    "        # Update the previous intent\n",
    "        if turn[\"speaker\"] == \"User\":\n",
    "            previous_intent = turn[\"intent\"]\n",
    "\n",
    "    return bert_input, labels\n",
    "\n",
    "with open(data_file, 'r') as f:\n",
    "    dialogues = json.load(f)\n",
    "\n",
    "def process_all_dialogues(data_file):\n",
    "    # Load the dataset\n",
    "    \n",
    "    all_bert_inputs = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # Process each dialogue in the dataset\n",
    "    for dialogue in dialogues:\n",
    "        bert_input, label = create_bert_input_split(dialogue)\n",
    "        all_bert_inputs.extend(bert_input)\n",
    "        all_labels.extend(label)\n",
    "    \n",
    "    return all_bert_inputs, all_labels\n",
    "\n",
    "\n",
    "# Get all data points for BERT\n",
    "all_bert_inputs, all_labels = process_all_dialogues(data_file)\n",
    "\n",
    "# Print the resulting data points (for example, print the first few data points)\n",
    "# for i, input_str in enumerate(all_bert_inputs):  # Limiting to the first 10 data points for viewing\n",
    "#     print(f\"Data point {i + 1}: {input_str}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[INT] [BOT]  [USR] Hey can i get the status of my latest order?', '[INT] track_order [BOT] Sure! Could you provide me with the order ID? [USR] Yeah, the order ID is 121212.', '[INT] [BOT]  [USR] I want to get the status of order 12121.', '[INT] [BOT]  [USR] Can you share the details of an order?', '[INT] track_order [BOT] Yeah can you provide me with the order ID? [USR] Yeah, I will share the order ID. It is 212131413.', '[INT] [BOT]  [USR] Could you tell me the status of my recent order?', '[INT] track_order [BOT] Sure! Could you provide me with the order ID? [USR] The order ID is 54321', '[INT] [BOT]  [USR] I want to know where my order is. Can you help me?', '[INT] track_order [BOT] Absolutely! Could you provide me with the order number? [USR] Yeah the order number is 987654321', '[INT] [BOT]  [USR] Can you provide me with an update on my order?']\n",
      "['track_order', 'give_order_id', 'track_order', 'track_order', 'give_order_id', 'track_order', 'give_order_id', 'track_order', 'give_order_id', 'track_order']\n"
     ]
    }
   ],
   "source": [
    "print(all_bert_inputs[:10])\n",
    "print(all_labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump this to a csv, first column is instructions and second is intent\n",
    "import csv\n",
    "\n",
    "# Output file path\n",
    "output_file = '../data/bert_input.csv'\n",
    "\n",
    "# Write the BERT input data to a CSV file\n",
    "with open(output_file, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"instruction\", \"intent\"])\n",
    "    for instruction, intent in zip(all_bert_inputs, all_labels):\n",
    "        writer.writerow([instruction, intent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'list_orders': 0, 'track_order': 1, 'give_order_id': 2, 'give_list_order_params': 3, 'give_reason': 4, 'confirm_command': 5, 'cancel_order': 6}\n"
     ]
    }
   ],
   "source": [
    "# get the number of intents\n",
    "unique_intents = set()\n",
    "for dialogue in dialogues:\n",
    "    for turn in dialogue[\"turns\"]:\n",
    "        if turn[\"speaker\"] == \"User\":\n",
    "            unique_intents.add(turn[\"intent\"])\n",
    "            \n",
    "num_intents = len(unique_intents)\n",
    "\n",
    "intent_to_label = {intent: i for i, intent in enumerate(unique_intents)}\n",
    "print(intent_to_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harshit/IITH/Sem7/CyberSecurityAndAI/cyber_security_project/chatbot_venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-11-27 21:11:39.454294: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-27 21:11:39.463302: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732722099.473462    6112 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732722099.476423    6112 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-27 21:11:39.488165: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "from transformers import BertForSequenceClassification, AdamW\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_data(data_points, max_length=128):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    labels = []\n",
    "\n",
    "    # Assuming 'data_points' is a list of formatted strings like '[INT] [BOT] [USR] ...'\n",
    "    for data in data_points:\n",
    "        # Tokenize and encode the data points\n",
    "        encoding = tokenizer(data, truncation=True, padding='max_length', max_length=max_length, return_tensors='pt')\n",
    "        \n",
    "        input_ids.append(encoding['input_ids'].squeeze())\n",
    "        attention_masks.append(encoding['attention_mask'].squeeze())\n",
    "        \n",
    "        # Labels: map intent names to integers\n",
    "        # Example: {\"track_order\": 0, \"give_order_id\": 1, ...}\n",
    "        intent = data.split()[1]  # Assuming the intent is always at index 1\n",
    "        labels.append(intent_to_label.get(intent, -1))  # Handle unknown intents with -1\n",
    "\n",
    "    return torch.stack(input_ids), torch.stack(attention_masks), torch.tensor(labels)\n",
    "\n",
    "# Create custom Dataset class\n",
    "class IntentDataset(Dataset):\n",
    "    def __init__(self, data_points, max_length=128):\n",
    "        self.data_points = data_points\n",
    "        self.max_length = max_length\n",
    "        self.input_ids, self.attention_masks, self.labels = preprocess_data(data_points, max_length)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_points)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.input_ids[idx],\n",
    "            'attention_mask': self.attention_masks[idx],\n",
    "            'labels': self.labels[idx]\n",
    "        }\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_data, val_data = train_test_split(all_bert_inputs, test_size=0.2)\n",
    "\n",
    "train_dataset = IntentDataset(train_data)\n",
    "val_dataset = IntentDataset(val_data)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained BERT for classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_intents)  # Adjust num_labels\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harshit/IITH/Sem7/CyberSecurityAndAI/cyber_security_project/chatbot_venv/lib/python3.12/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "{'list_orders': 0, 'track_order': 1, 'give_order_id': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Target -1 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 61\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Training phase\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(intent_to_label)\n\u001b[0;32m---> 61\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Evaluation phase\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 16\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, criterion, device)\u001b[0m\n\u001b[1;32m     13\u001b[0m labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[1;32m     18\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/IITH/Sem7/CyberSecurityAndAI/cyber_security_project/chatbot_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/IITH/Sem7/CyberSecurityAndAI/cyber_security_project/chatbot_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/IITH/Sem7/CyberSecurityAndAI/cyber_security_project/chatbot_venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1703\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1701\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mproblem_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle_label_classification\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1702\u001b[0m     loss_fct \u001b[38;5;241m=\u001b[39m CrossEntropyLoss()\n\u001b[0;32m-> 1703\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mproblem_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti_label_classification\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1705\u001b[0m     loss_fct \u001b[38;5;241m=\u001b[39m BCEWithLogitsLoss()\n",
      "File \u001b[0;32m~/IITH/Sem7/CyberSecurityAndAI/cyber_security_project/chatbot_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/IITH/Sem7/CyberSecurityAndAI/cyber_security_project/chatbot_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/IITH/Sem7/CyberSecurityAndAI/cyber_security_project/chatbot_venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:1293\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/IITH/Sem7/CyberSecurityAndAI/cyber_security_project/chatbot_venv/lib/python3.12/site-packages/torch/nn/functional.py:3479\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3478\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3479\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3480\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3482\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3483\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3486\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: Target -1 is out of bounds."
     ]
    }
   ],
   "source": [
    "# Define optimizer and loss function\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training function\n",
    "def train(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_loader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    return avg_loss\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, val_loader, device):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # Prediction\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "\n",
    "            total_correct += torch.sum(preds == labels)\n",
    "            total += labels.size(0)\n",
    "\n",
    "    accuracy = total_correct / total\n",
    "    return accuracy.item()\n",
    "\n",
    "# Train and evaluate the model\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    \n",
    "    # Training phase\n",
    "    print(intent_to_label)\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, device)\n",
    "    print(f\"Training Loss: {train_loss:.4f}\")\n",
    "    \n",
    "    # Evaluation phase\n",
    "    accuracy = evaluate(model, val_loader, device)\n",
    "    print(f\"Validation Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
